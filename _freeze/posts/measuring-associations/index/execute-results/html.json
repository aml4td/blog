{
  "hash": "ec74ef30021ffb88436a0092a1e29010",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Measuring Associations\"\nauthor: \"Max Kuhn\"\ndate: \"2013-06-21\"\ncategories:\n  - R\n  - association\n  - blood-brain barrier\n  - MIC\n  - RRelief\ndraft: false\n--- \n\n\n<hr>\n\n\n::: {.cell}\n\n:::\n\n\nIn Chapter 18, we discuss a relatively new method for measuring predictor importance called the maximal information coefficient (MIC). The original paper is by [Reshef at al (2011)](http://scholar.google.com/scholar?q=%22DETECTING+NOVEL+ASSOCIATIONS+IN+LARGE+DATA+SETS%22). \n\nA summary of the initial reactions to the MIC are [Speed](http://www.sciencemag.org/content/334/6062/1502.short) and [Tibshirani](http://www-stat.stanford.edu/~tibs/reshef/comment.pdf) (and others can be found [here](http://scholar.google.com/scholar?cites=17152416007763542209&as_sdt=8005&sciodt=0,7&hl=en)). My (minor) beef with it is the lack of a probabilistic motivation. The authors have some general criteria (generality and equitability) and created an algorithm that seems to good in terms of these properties. The MIC clearly works, but what is it really optimizing and why?\n\nIt reminds me of partial least squares. The algorithm made intuitive sense and obviously worked, but it was a while before anyone actually figured out what mathematical problem it was solving. A similar statement could be made about boosting when it was first developed. \n\n[Murrell et al (2013)](http://arxiv.org/abs/1303.1828) (or Murrell<sup>3</sup>?) has a similar generalized measure of association between continuous variables. There's is based on a generalized notion of R<sup>2</sup> that I'd never heard of. At first glance, it has a lot of attractive properties. One is that is has a probabilistic genesis. Another nice quality is that the association can be computed while controlling for other data. That is a big deal for me, since we often have experiments where we need to control for nuisance factors. For example, if you were trying to measure the relationship between the selling price of a house and the acerage of the lot, you might want to control for other factors, such as the type of terrain or geography (e.g. urban, rural etc).    \n\nDespite the probabilistic motivation, they take a randomization approach to making formal statistical inferences on significance of the measure. The same could be done for the MIC measure (and in the book, we used the same idea for Relief scores).  I think a confidence interval would be better for everyone since it directly tells you the uncertainty and the size of the association (that's another post for another time for a topic that has been [discussed](http://news.sciencemag.org/sciencenow/2009/10/30-01.html) [quite](http://www.reanimacao.com.br/biblioteca/a_20100121_04.pdf) [a](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2352195/pdf/bmj00561-0050.pdf) [bit](http://www.physther.org/content/81/8/1464.full)).\n\nLet's look at some data. I like the blood-brain barrier data a lot. It has measurements on 208 drugs to see how much (if at all) they enter the brain. The predictors are molecular descriptors (similar to the solubility example in the book). To get the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: ggplot2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: lattice\n```\n\n\n:::\n\n```{.r .cell-code}\ndata(BloodBrain)\n## remove zero variance columns\nisZV <- apply(bbbDescr, 2, function(x) length(unique(x)) == 1)\nbbbDescr <- bbbDescr[, !isZV]\nncol(bbbDescr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 134\n```\n\n\n:::\n:::\n\n\nFirst, I'll measure association using the _A_ measure discussed in Murrell<sup>3</sup>:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(matie)\n## Compute the associations across all columns of the predictors\nAvalues <- apply(bbbDescr, 2, function(x, y) ma(cbind(x, y))$A, y = logBBB)\nAvalues <- sort(Avalues, decreasing = TRUE)\nhead(Avalues)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     fnsa3   psa_npsa polar_area       tpsa      scaa3       tcnp \n 0.4381135  0.4140194  0.4136030  0.3847299  0.3766920  0.3691589 \n```\n\n\n:::\n:::\n\n\nSo the best predictor only explains 43.9% of the variation in the outcome. Most of the predictors shown above are related to surface area, which makes sense: the larger the molecule the less likely it is to physically fit through the barrier. \n\nWhat does MIC tell us?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(minerva)\n## There are three predictors whose scales have very low variances. We\n## need to reset the threshold that checks for this\nmic <- mine(bbbDescr, logBBB, var.thr = 1e-10)$MIC\nmic <- mic[, \"Y\"]\nnames(mic) <- colnames(bbbDescr)\nmic <- mic[order(mic, decreasing = TRUE)]\nhead(mic)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    fnsa3      rpcg     fpsa3     scaa1     scaa3  psa_npsa \n0.5248916 0.4806339 0.4761844 0.4758696 0.4711854 0.4650277 \n```\n\n\n:::\n:::\n\n\nThere are some differences but the top predictor from _A_ is still at the top. The MIC values is sort of a correlation-like measure and our best value was 0.52.\n\nI also have a measure of importance that is based on scatterplot smoothers. A loess smoother is fit between the outcome and the predictor and the R<sup>2</sup> statistic is calculated for this model against the intercept only null model. I don't claim that there is any justification (which is why I've never published it) for this but it has worked for me in the past. This is similar to my statements about MIC and PLS. I still use them because they tend to work, but I've no theoretical leg to stand on. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## A measure based on regression smoothers\ngamImp <- filterVarImp(bbbDescr, logBBB, nonpara = TRUE)\ngamImp <- gamImp[order(gamImp$Overall, decreasing = TRUE), , drop = FALSE]\nhead(gamImp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             Overall\nfnsa3      0.3970318\npsa_npsa   0.3879014\npolar_area 0.3805523\ntcnp       0.3681280\ntpsa       0.3584280\ntpsa.1     0.3474503\n```\n\n\n:::\n:::\n\n\nFinally, I'll compute the RRelief scores. We discuss this in the book and the a good reference is [here](http://lkm.fri.uni-lj.si/xaigor/slo/clanki/MLJ2003-FinalPaper.pdf). It uses a nearest-neighbor approach and measures the importance of each predictors simultaneously (all of the other methods show here measure each association in isolation).  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(CORElearn)\n\n## The function only uses the formula interface\nbbbData <- bbbDescr\nbbbData$logBBB <- logBBB\n\nset.seed(10)\nRRelief <- attrEval(logBBB ~ ., data = bbbData, estimator = \"RReliefFbestK\", \n                    ReliefIterations = 100)\nRRelief <- RRelief[order(RRelief, decreasing = TRUE)]\nhead(RRelief)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     smr_vsa7      smr_vsa1 dipole_moment    peoe_vsa.0           pol \n    0.2622103     0.2577087     0.2524930     0.2452446     0.2366486 \n     smr_vsa6 \n    0.2278432 \n```\n\n\n:::\n:::\n\n\nThis score ranks the variables differently than the other methods. This is most likely due to the difference in philosophy in measuring association between this method and the others as well as the high degree of correlation between the predictors in these data. \n\nOverall, do these metrics correlate?\n\n![](splom.png){fig-align=\"center\"}\n\nIf you ignore RRelief, there is some association between measures of association. Interestingly, there are a few predictors that have zero association using the _A_ measure but non-zero correlation using MIC. The variables, and their MIC values are: `peoe_vsa.2` (0.22), `slogp_vsa4` (0.2), `peoe_vsa.0` (0.19), `smr_vsa1` (0.18), `a_acid` (0.18), `peoe_vsa.2.1` (0.14) and `negative` (0.04). What do these look like? Here are scatterplots between these predictions and the outcome (with scatterplot smoother fits):\n\n![](scat.png){fig-align=\"center\"}\n\nSeveral of these are \"near zero variance\" predictors and probably shouldn't be evaluated. For this image, it is difficult for me to see the association between the response and `peoe_vsa.0` (MIC = 0.19) or `smr_vsa1` (MIC = 0.18).\n\n(This article was originally posted at [`http://appliedpredictivemodeling.com`](https://appliedpredictivemodeling.com/blog/2013/6/6/jmt8dw6egtv977chpxs1oulmgy7ubx))\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}