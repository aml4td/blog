<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Applied Predictive Modeling Blog</title>
<link>https://blog.aml4td.org/</link>
<atom:link href="https://blog.aml4td.org/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.4.555</generator>
<lastBuildDate>Tue, 18 Jun 2024 04:00:00 GMT</lastBuildDate>
<item>
  <title>Progress Update (June 2024)</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/2024-06-progress-update/</link>
  <description><![CDATA[ 




<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/2024-06-progress-update/anime_barley_pca.gif" class="quarto-figure quarto-figure-center figure-img" height="350"></p>
</figure>
</div>
<p>We just released a new set of chapters:</p>
<ul>
<li><em>Embeddings</em>: this encompasses feature extraction tools such as PCA, MDS, UMAP, and shrunken centroids.</li>
<li><em>Interactions and Nonlinear Features</em>: interaction definitions and detection methods, basis expansions (polynomials, splines), and discretization.</li>
<li><em>Overfitting</em>: the first chapter of the “Optimization” part of the book. This sets up the next few chapters on resampling and model tuning.</li>
</ul>
<p>We liberally used <a href="https://quarto.org/docs/blog/posts/2022-10-25-shinylive-extension/">shinylive</a> to include interactive demonstrations of a few concepts, such as <a href="http://localhost:5999/chapters/embeddings.html#fig-umap">UMAP parameters</a> and <a href="http://localhost:5999/chapters/interactions-nonlinear.html#fig-natural-cubic-spline">natural splines</a>. It will be interesting when we convert this to a pdf for publishing but, overall, it has been a <a href="https://topepo.github.io/2024_05_NYR/#/title-slide">great tool to work with</a> and we think that it is a great tool for learning.</p>
<p>We still have one more chapter in the “Preparation” part on missing data. The chapter number for Overfitting will increment by one in the next release.</p>
<section id="what-we-are-working-on-now" class="level2">
<h2 class="anchored" data-anchor-id="what-we-are-working-on-now">What We Are Working On Now</h2>
<ul>
<li>Light/dark mode: <a href="https://www.karlton.org/2017/12/naming-things-hard/">Phil Karlton said</a> that “There are only two hard things in Computer Science: cache invalidation and naming things.” Maybe the third is getting an elegant framework for seemlessly going between light and dark mode. Quarto makes it a lot easier (and hopefully will become trival) but it is <em>not</em> easy. I have a <a href="https://topepo.github.io/light-dark-test/">test repo</a> started and a branch for this book to experiment with.</li>
<li>A missing data chapter.</li>
<li>A broad overview of resampling methods.</li>
<li>Grid search (including nested resampling, racing).</li>
<li>Iterative search.</li>
</ul>


</section>

 ]]></description>
  <category>preprocessing</category>
  <category>updates</category>
  <guid>https://blog.aml4td.org/posts/2024-06-progress-update/</guid>
  <pubDate>Tue, 18 Jun 2024 04:00:00 GMT</pubDate>
  <media:content url="https://blog.aml4td.org/posts/2024-06-progress-update/anime_barley_pca.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Data Usage with Postprocessing</title>
  <dc:creator>Max Kuhn</dc:creator>
  <dc:creator>Simon Couch</dc:creator>
  <link>https://blog.aml4td.org/posts/data-usage-for-postprocessors/</link>
  <description><![CDATA[ <p>This document is used to discuss and test ideas for how have can estimate and evaluate machine learning models that have three potential components:</p>
<ul>
<li>
<em>Preprocessors</em> are sequential operations that prepare predictor data for use in a supervised model. Examples are centering/scaling, PCA feature extraction, and so on.</li>
<li>A <em>supervised ML model</em> to translate the predictors to predictions of the outcome (e.g., logistic regression, random forest, etc.).</li>
<li>
<em>Postprocessors</em> that take the model’s predictions and change them for the purpose of improving model performance. One example is choosing an <a href="https://blog.aml4td.org/posts/optimizing-probability-thresholds-for-class-imbalances/index.html">alternate probability cutoff</a> in binary classification to optimize for better true positive or true negative rates.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>We’ll call the combination of these three components the <em>model pipeline</em><sup>1</sup>:</p>
<pre><code>   pipeline = preprocessor(s) + supervised model + postprocessor(s)</code></pre>
<p>The pipeline includes the model in the least; the pre and post model operations are added as needed.</p>
</div>
</div>
<p>We want feedback, so if you like our recommendations or have alternatives, <strong>please comment below</strong>.</p>
<p>Let’s take some time to describe what postprocessors can do.</p>
<section id="more-about-postprocessors" class="level2"><h2 class="anchored" data-anchor-id="more-about-postprocessors">More About Postprocessors</h2>
<p>The process of postprocessing the predicted values has not been thoroughly discussed, mostly because the software to operationalize the full pipeline process is not comprehensive.</p>
<p>The number of potential postprocessors is probably in single digits. Some examples:</p>
<ul>
<li>Specifying an optimal probability cutoff (mentioned above).</li>
<li>Restricting the range of possible predictions (e.g., greater than zero).</li>
<li>Simple deterministic transformations (e.g., exponentiation of predicted values).</li>
<li>Disqualifying predictions via an <a href="https://blog.aml4td.org/posts/equivocal-zones/index.html">equivocal zone</a>.</li>
<li>Post-hoc nearest neighbor adjustments such as <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Combining+instance-based+and+model-based+learning&amp;btnG=">Quinlan (1993)</a>.</li>
<li>
<a href="https://www.tidyverse.org/blog/2022/11/model-calibration/">Calibration</a>.</li>
</ul>
<p>Each of these steps can involve tuning parameters that require optimization. For example, we can vary the cutoff value over a range for alternate probability cutoffs and measure the performance change in some statistic that uses the hard class predictions (such as accuracy or Kappa). These types of parameters are estimated <em>indirectly</em> via grid search or some other tuning parameter optimization routine. There is no analytical formula where we plug in our predictor and outcome data to produce a point estimate to plug into the postprocessor.</p>
<p>However, the last two in the list above might also have parameter values that require direct estimation (akin to slope parameters in a linear regression). Of these, let’s focus on <em>model calibration</em> for more discussion.</p>
<section id="model-calibration" class="level4"><h4 class="anchored" data-anchor-id="model-calibration">Model Calibration</h4>
<p>This article focuses largely on model calibration. This technique is not particularly significant, but we use it because it is a well-known postprocessing technique that requires direct parameter estimation.</p>
<p>Calibration is most often applied to classification models. To keep things relatively simple, we’ll demonstrate the problem with a regression model that predicts a numeric outcome.</p>
<p>We’ll use a regression data set as a demonstration<sup>2</sup>. The data were split into a training set (n = 6004), a validation set (n = 2004), and a test set (n = 2004). This data splitting scheme corresponds to Case 5 below. The outcome is numeric and there are 30 predictors.</p>
<p>Let’s deliberately fit a regression model that has poor predicted values: a boosted tree with only five members. The validation set statistics show an RMSE of 4.71 (units are minutes) and a corresponding R<sup>2</sup> of 85.4%. It’s hard to know if the RMSE is acceptable without context but the latter statistic seems pretty good.</p>
<p>However, when we look at the data, the observed and predicted values are well correlated but very poorly calibrated:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="https://blog.aml4td.org/posts/data-usage-for-postprocessors/index_files/figure-html/bad-pred-plot-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
</div>
</div>
<p>The predicted values are not realistic in the sense that they are not consistent with the original data. They should fall along the diagonal green line if the model is performing well.</p>
<p>The solid blue curve above shows a linear regression line that is fit to these data. This measures the systematic miscalibration. If we were to use the validation set to quantify the pattern, the intercept was -39.2 minutes and the slope was 2.49 minutes. Now that we know this pattern, it might be possible to remove it from the predictions.</p>
<p>The problem, more broadly described below in Case 3, is that we can’t use the validation set to measure this pattern and assess its effectiveness.</p>
<p>As an alternative, we used a slightly risky approach described in Case 3 to estimate a slope of -38.7 minutes, and the slope was 2.48 minutes. When these values are used to correct the validation set predictions, RMSE decreases from 4.71 to 2.68 minutes. The R<sup>2</sup> stays the same.</p>
<p>The plot of the calibrated predictions shows a moderately effective model that has much better calibration:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="https://blog.aml4td.org/posts/data-usage-for-postprocessors/index_files/figure-html/cal-pred-plot-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
</div>
</div>
</section><section id="our-goals-here" class="level4"><h4 class="anchored" data-anchor-id="our-goals-here">Our Goals Here</h4>
<p>In this article, we want to examine the nuances of data usage in situations where our pipeline is trained in two stages. To do this, we’ll show some diagrams that illustrate some different strategies. The discussion of different data spending schemes with an initial pool of 100 samples, assumed to be in a random order, is visualized using:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="https://blog.aml4td.org/posts/data-usage-for-postprocessors/premade/sample-pool.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
</div>
</div>
<p>Let’s start with the ordinary case where we use a simple two-way training/testing split of the data, then consider different analysis paths.</p>
</section></section><section id="initial-two-way-split" class="level2"><h2 class="anchored" data-anchor-id="initial-two-way-split">Initial Two-Way Split</h2>
<p>There are a few different scenarios to consider. The first two are very pedestrian and are only included to contrast with the more complex ones.</p>
<section id="case-1-no-tuning-no-postprocessing-estimation" class="level4"><h4 class="anchored" data-anchor-id="case-1-no-tuning-no-postprocessing-estimation">Case 1: No Tuning, No Postprocessing Estimation</h4>
<p>This is a simple case where a basic model will suffice with tuning parameters and no uncertainty about what predictors should be in the model.</p>
<p>“No Postprocessing Estimation” means that there might be a postprocessor but it does not require any parameter estimation. For example, it might just change the probability cutoff for a binary classification to be something other than 50%.</p>
<p>We split the data into a larger set (training, in orange), and the remainder goes into testing (purple). Any 80/20 split is used to demonstrate:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="https://blog.aml4td.org/posts/data-usage-for-postprocessors/premade/no-estimation-split.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
</div>
</div>
<p>All of our estimation tasks use the training set and the test set is evaluated only once to quantify the efficacy of the model.</p>
</section><section id="case-2-tuning-no-postprocessing-estimation" class="level4"><h4 class="anchored" data-anchor-id="case-2-tuning-no-postprocessing-estimation">Case 2: Tuning, No Postprocessing Estimation</h4>
<p>Here, some aspects of the model, preprocessor, or postprocessor required optimization. Any postprocessor does not require estimation (but could require tuning).</p>
<p>Using the same initial split from Case 1, we might use some resampling strategy like cross-validation, the bootstrap, or a time-series resampling scheme. Without loss of generalization, we’ll show a 5-fold cross-validation diagram:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="https://blog.aml4td.org/posts/data-usage-for-postprocessors/premade/training-to-5-fold.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:45.0%"></p>
</figure>
</div>
</div>
</div>
<p>As usual, we fit five model pipelines with different tuning parameter candidates. Each model uses 4/5 of the data for estimation and the remaining 1/5 to measure performance. The resulting five performance statistics are averaged into a single value, which is used to guide the user in picking which tuning parameters are optimal (or at least reasonable).</p>
<p>Once the optimization phase is finished, the final model uses the optimized tuning parameter values and is fit to the 80 data points of the training set. The other 20 samples in the test set are used to verify performance.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note that we use specific terminology to distinguish between the data used for modeling and evaluation at the two different levels of data partitioning. The initial split creates training and test sets. During resampling, the analogs to these data sets are called the <em>analysis</em> and <em>assessment</em> sets.</p>
</div>
</div>
</section><section id="case-3-no-tuning-postprocessing-estimation" class="level4"><h4 class="anchored" data-anchor-id="case-3-no-tuning-postprocessing-estimation">Case 3: No Tuning, Postprocessing Estimation</h4>
<p>Here our model pipeline requires no tuning but we do need to estimate parameters for our postprocessor.</p>
<p>For example, perhaps our ordinary least squares linear regression model has some systematic bias in the predictions (and we have to use this model). We could attach a linear calibrator to the model pipeline that estimates the slope and intercept of a line defined by the observed and predicted outcomes (as shown above).</p>
<p>We need data to estimate the slope and intercept. We should not touch the test set. Naively re-predicting the training set is a poor choice; for many black-box models, the fitted values will be unreasonably close to the true values. This means that the systematic bias that we are trying to remove will be less pronounced and the calibration may not help. It also leaves us with no other data to judge how well the model (and calibration) works without using the test set.</p>
<p>One possible approach is to resample the model (prior to the calibration set) using the approach in Case 2. This can produce the out-of-sample predictions that were used to produce the resampled performance statistic. These values are not overfit to the training data and should be a reasonable substrate to fit the calibration model. The main downside to this approach is that we are “double dipping” on the training set but using it to</p>
<ol type="1">
<li>Estimate our model parameters, and</li>
<li>Estimate the calibration parameters.</li>
</ol>
<p>This raises the risk of overfitting and we don’t have a data set to check how well this works until the test set (which should be used to verify performance). This is the approach that was used in the regression calibration example above.</p>
<p>Another approach is to use a three-way split at the start instead of a basic training/test set. We could reserve some data strictly for calibration (assuming that we know that calibration is required).</p>
<p>We can allocate a small fraction of data for postprocessing estimation. A diagram of this is before with 60% used for training the preprocessor and supervised model, 20% for estimating the postprocessor, and 20% for testing<sup>3</sup>. In the diagram below, the two shades of brown are meant to reflect that these data are used for estimation and the purple data are used strictly for model evaluation.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="https://blog.aml4td.org/posts/data-usage-for-postprocessors/premade/with-estimation-split.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:45.0%"></p>
</figure>
</div>
</div>
</div>
<p>The nomenclature is a little bit fuzzy here. For now, we’ll call the darker brown data the training set (no different than before), the purple data the standard test set, and the light brown data the “<strong>potato set</strong>”<sup>4</sup></p>
<p>This extra set is a simple solution that avoids potential data leakage but is reducing the amount of data used to train the preprocessors and the supervised model.</p>
<p>The next use-case is for situations where the model needs to be resampled for tuning or just to get some estimate of model performance.</p>
</section><section id="case-4-tuning-postprocessing-estimation" class="level4"><h4 class="anchored" data-anchor-id="case-4-tuning-postprocessing-estimation">Case 4: Tuning, Postprocessing Estimation</h4>
<p>Now our model and/or preprocessor have unknown parameters that need to be indirectly optimized via grid search, Bayesian optimization, or by some other means. The compare and choose between models, we require an out-of-sample performance estimate, just as in Case 2.</p>
<p>The difference here is the existence of a postprocessor that needs estimation.</p>
<p>Once we arrive at our final tuning parameter value(s), we still need to perform the “last fit” where we estimate all of the parameters for the entire model pipeline.</p>
<p>Let’s say we use the three-way data splitting scheme shown above in Case 3. How do we resample the model? We suggest taking <em>all</em> data that are not used for the testing set as the substrate for resampling. Let’s again use 5-fold cross-validation to demonstrate. The 80 samples are allocated to one of five folds.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="https://blog.aml4td.org/posts/data-usage-for-postprocessors/premade/training-reserve-to-5-fold.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:45.0%"></p>
</figure>
</div>
</div>
</div>
<p>For the first iteration of cross-validation, we take out the first fold earmarked for performance estimation as the assessment set.</p>
<p>Ordinarily, the other 4/5 would be used to estimate the preprocessor(s) and the model. However, doing so in this case would result in overly optimistic performance statistics; assuming we always retain 1/5 of this data for model assessment, using the remaining 4/5 to estimate the preprocessor(s) and model would require that we train the postprocessor on predictions generated on that same 4/5 of the fold. Instead, we allot some portion of that 4/5—say, 3/4 of it—to train the preprocessor(s) and model, then generate predictions on the held-out 1/4 from the trained preprocessor(s) and model, then use <em>those</em> predictions to train the postprocessor. Then, the trained preprocessor(s), model, and postprocessor generate predictions on the remaining 1/5 of the fold that are evaluated using performance metrics.</p>
<p>We can emulate the same procedure used in our initial three-way split by randomly<sup>5</sup> selecting the same proportion of data to estimate the two estimation stages.</p>
<p>Visually, the scheme for the first iteration of cross-validation is:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="https://blog.aml4td.org/posts/data-usage-for-postprocessors/premade/reserve-in-cv-iter-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
</div>
</div>
<p>In this instance, five preprocessor/model fits are paired with five calibration models, and when combined in sequence, they produce five resampled performance statistics. This is a complete resampling of the process that avoids information leakage.</p>
</section></section><section id="initial-three-way-split" class="level2"><h2 class="anchored" data-anchor-id="initial-three-way-split">Initial Three-Way Split</h2>
<p>If we have a lot of data, we might choose to start with three partitions of our data pool. The standard training and test sets would be supplemented by a validation set. This serves as a separate group of points that are used to judge model effectiveness during model development. While we should only look at the test set once, the validation set is designed to be evaluated multiple times so that we can compare and/or optimize our pipeline. Here’s a view of a 65/15/20 split:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="https://blog.aml4td.org/posts/data-usage-for-postprocessors/premade/val-split.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
</div>
</div>
<p>During model development, we can view the validation set as if it were a single iteration of resampling. Let’s look at that first.</p>
<section id="case-5-no-postprocessing-estimation" class="level4"><h4 class="anchored" data-anchor-id="case-5-no-postprocessing-estimation">Case 5: No Postprocessing Estimation</h4>
<p>During model development, we would train our pipeline on the 65% of the data reserved for that purpose. Assuming that we need to tune or compare models, we would predict the 15% validation set and compute performance statistics.</p>
<p>Eventually, we determine the best model pipeline to finalize. At this point, we already have our model fit since we have been directly training our pipeline on the training set<sup>6</sup>. From here, we predict the test set and verify that our validation set statistics were accurate.</p>
</section><section id="case-6-postprocessing-estimation" class="level4"><h4 class="anchored" data-anchor-id="case-6-postprocessing-estimation">Case 6: Postprocessing Estimation</h4>
<p>The situation here is basically the same as the Case 3; we don’t want to re-use our training set to fit the postprocessor. As with Case 3, we advocate for splitting off a fourth partition of data for that purpose. Here is an example of a 50/15/15/20 split:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="https://blog.aml4td.org/posts/data-usage-for-postprocessors/premade/four-way-split.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
</div>
</div>
<p>During model development,</p>
<ol type="1">
<li>The preprocessor and supervised model are training on the training set (50% here)</li>
<li>The predictions on the potato set (15%) are used as inputs to estimate the postprocessing parameters.</li>
<li>The completely fitted pipeline predicts the validation set (15%), and those performance statistics guide our decision to finalize the pipeline.</li>
<li>The test set (20%) is evaluated once for verification of performance.</li>
</ol>
<p>That is a lot of splitting but our pipeline is pretty complex. One might think that we are significantly reducing the amount of data used to fit the supervised models. That’s correct, and hopefully, it emphasizes that as the complexity of our pipeline increases, our data usage strategy needs to be more extensive to avoid subtle overfitting errors.</p>
</section></section><section id="summary-tldr" class="level2"><h2 class="anchored" data-anchor-id="summary-tldr">Summary (tl;dr)</h2>
<p>We’ve described how postprocessing operations can fit into the machine learning pipeline and the complications that occur in terms of data usage. From the viewpoint of the data, there are two main phases of pipeline training:</p>
<ul>
<li>
<p><strong>Stage 1</strong>: Use a single set of data to train the preprocessors (if any) and the supervised model.</p>
<ul>
<li>The inputs are predictors and outcome data.</li>
<li>Outputs are model predictions.</li>
</ul>
</li>
<li>
<p><strong>Stage 2</strong>: Use a separate set of training data to estimate any postprocessors (if any).</p>
<ul>
<li>Inputs are model predictions.</li>
<li>Outputs are modified model predictions.</li>
</ul>
</li>
</ul>
<p>We recommend using two different partitions for each of these two stages.</p>
<p>Thanks to the tidymodels group for review of this post, especially Simon Couch who also edited the <a href="https://github.com/topepo/postprocessing-data">original source of this post</a>.</p>
<p>EDIT: Simon really deserved to be an author of this post since he was more involved in the development of these ideas than the original post made it sound. I’ve added him as an author.</p>


</section><div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>
<ol>
<li id="fn1"><p>This document is intended to be independent of implementations. The phrase <em>model pipeline</em> is based on sci-kit learn’s object type. tidymodels calls it a <em>model workflow</em> and only uses different terminology to avoid confusion with the <a href="https://magrittr.tidyverse.org/reference/pipe.html">magrittr pipeline</a>.↩︎</p></li>
<li id="fn2"><p>These data are originally from <a href="https://aml4td.org/chapters/whole-game.html">the <em>Whole Game</em> chapter</a>.↩︎</p></li>
<li id="fn3"><p>Again, we don’t have to do this for all postprocessors, just those that require parameters to be estimated↩︎</p></li>
<li id="fn4"><p>Obviously, this is not going to be the real name. We need a placeholder until we come up with something that we all like. Potential candidate names are the “reserved data,” auxiliary data,” and “supplemental data. Why <em>potato</em>? Because it is easy to find/replace and you will probably remember it.”↩︎</p></li>
<li id="fn5"><p><em>Most of the time</em>, this will be done via random sampling. For time-series data, we would emulate the same non-random splitting strategy that does not break the correlation structure of the data. Also, if we are bootstrapping, the proportional splits are conducted on the distinct rows of the non-test data to avoid having some replicates of specific rows falling in both partitions of the data.↩︎</p></li>
<li id="fn6"><p>Since the validation set is no longer required, some people might pool the training and validation set and fit the finalized pipeline on those data (80% in total in our example). I don’t think that it’s a good idea but it does happen.↩︎</p></li>
</ol></section></div> ]]></description>
  <category>preprocessing</category>
  <category>data-splitting</category>
  <category>resampling</category>
  <guid>https://blog.aml4td.org/posts/data-usage-for-postprocessors/</guid>
  <pubDate>Tue, 07 May 2024 04:00:00 GMT</pubDate>
</item>
<item>
  <title>
Post Hoc Nearest Neighbors Prediction Adjustments</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/post-hoc-nearest-neighbors-prediction-adjustments/</link>
  <description><![CDATA[ <hr>
<p><a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Combining+instance-based+and+model-based+learning&amp;btnG=">Quinlan (1993)</a> describes a post-processing technique used for numeric predictions that adjusts them using information from the training set.</p>
<p>Let’s say you have some model with a numeric outcome <img src="https://latex.codecogs.com/png.latex?y"> and a vector of predictors <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7Bx%7D">. We’ve fit some model to the training set and we have a new observation with predictors <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7Bx%7D_0">; the model’s prediction is <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7By%7D_0">.</p>
<p>This method finds the <img src="https://latex.codecogs.com/png.latex?K">-nearest neighbors to <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7Bx%7D_0"> from the training set (denotes as <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7Bx%7D_1%5Cldots%20%5Cboldsymbol%7Bx%7D_K">) and their corresponding predictions <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7By%7D_i">. The distances from the new sample to the training set points are <img src="https://latex.codecogs.com/png.latex?d_i">.</p>
<p>For the new data point, the <img src="https://latex.codecogs.com/png.latex?K"> adjusted predictions are:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cwidehat%7Ba%7D_i%20=%20y_i%20+%20(%5Cwidehat%7By%7D_0%20-%20%5Cwidehat%7By%7D_i)%0A"></p>
<p>for <img src="https://latex.codecogs.com/png.latex?i=1%5Cldots%20K">. The final prediction is the weighted average the <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7Ba%7D_i"> where the weights are <img src="https://latex.codecogs.com/png.latex?w_i%20=%201%20/%20(d_i%20+%20%5Cepsilon)">. <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> is there to prevent division by zero and Quinlan defaults this to 0.5.</p>
<p>Suppose the true value of the closest neighbor is 10 and its prediction is 11. If our new value <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7Bx%7D_0"> is over-predicted with a value of 15, we end up adjusting the prediction down to 14 (i.e., 10 + (15 - 11)).</p>
<p>This adjustment is an integral part of the Cubist rule-based model ensemble that we discuss in <a href="http://appliedpredictivemodeling.com/"><em>APM</em></a> (and will later in this book). We’d like to apply it to any regression model.</p>
<p>To do this in general, I’ve started a small R package called <a href="https://topepo.github.io/adjusted/">adjusted</a>. It requires a fitted tidymodels workflow object and uses <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Some+distance+properties+of+latent+root+and+vector+methods+used+in+multivariate+analysis&amp;btnG=">Gower distance</a> for calculations.</p>
<p>Here’s an example using MARS on the <a href="https://aml4td.org/chapters/whole-game.html#sec-delivery-times">food delivery data</a>:</p>
<div class="cell">
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>✔ broom        1.0.5      ✔ recipes      1.0.10
✔ dials        1.2.1      ✔ rsample      1.2.1 
✔ dplyr        1.1.4      ✔ tibble       3.2.1 
✔ ggplot2      3.5.0      ✔ tidyr        1.3.1 
✔ infer        1.0.6      ✔ tune         1.2.0 
✔ modeldata    1.3.0      ✔ workflows    1.1.4 
✔ parsnip      1.2.1      ✔ workflowsets 1.1.0 
✔ purrr        1.0.2      ✔ yardstick    1.3.1 </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ purrr::discard() masks scales::discard()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
✖ recipes::step()  masks stats::step()
• Learn how to get started at https://www.tidymodels.org/start/</code></pre>
</div>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Found at https://github.com/topepo/adjusted</span></span>
<span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">adjusted</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span>
<span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Also requires the earth package</span></span>
<span></span>
<span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://tidymodels.tidymodels.org/reference/tidymodels_prefer.html">tidymodels_prefer</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span>
<span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://ggplot2.tidyverse.org/reference/theme_get.html">theme_set</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
</div>
<p>The data are in the modeldata package. We’ll do the same split as the book (training/validation/testing):</p>
<div class="cell">
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">deliveries</span>, package <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"modeldata"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span>
<span></span>
<span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">991</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span>
<span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">delivery_split</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://rsample.tidymodels.org/reference/initial_validation_split.html">initial_validation_split</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">deliveries</span>, prop <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span>,</span>
<span>                                           strata <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">time_to_delivery</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span>
<span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">delivery_train</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://rsample.tidymodels.org/reference/initial_split.html">training</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">delivery_split</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span>
<span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">delivery_test</span>  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://rsample.tidymodels.org/reference/initial_split.html">testing</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">delivery_split</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span>
<span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">delivery_val</span>   <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://rsample.tidymodels.org/reference/initial_validation_split.html">validation</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">delivery_split</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
</div>
<p>Let’s specify a <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=%22multivariate+adaptive+regression+spline%22+Friedman&amp;btnG=">multivariate adaptive regression spline</a> model that can utilize two-factor interaction terms. The initial code is pretty simple:</p>
<div class="cell">
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">mars_spec</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;-</span>  </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://parsnip.tidymodels.org/reference/mars.html">mars</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>prod_degree <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://parsnip.tidymodels.org/reference/set_args.html">set_mode</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"regression"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span>
<span></span>
<span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">mars_fit</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://workflows.tidymodels.org/reference/workflow.html">workflow</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://workflows.tidymodels.org/reference/add_formula.html">add_formula</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">time_to_delivery</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">.</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://workflows.tidymodels.org/reference/add_model.html">add_model</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">mars_spec</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://generics.r-lib.org/reference/fit.html">fit</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">delivery_train</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
</div>
<p>We can use the earth package’s <code><a href="https://rdrr.io/r/base/format.html">format()</a></code> function to see the model terms/splits. It’s fairly long though:</p>
<details><div class="cell">
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">mars_fit</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://hardhat.tidymodels.org/reference/hardhat-extract.html">extract_fit_engine</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://rdrr.io/r/base/format.html">format</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>digits <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  53
  -  0.456 * dayTue
  +   3.48 * dayWed
  +   5.97 * dayThu
  +   10.6 * dayFri
  +   15.1 * daySat
  +   3.68 * daySun
  -   1.13 * h(hour-16.233)
  -   2.35 * h(17.319-hour)
  +  0.466 * h(hour-17.319)
  -   2.57 * h(3.84-distance)
  +   3.99 * h(distance-3.84)
  -  0.563 * h(2-item_02)
  +   4.22 * h(item_02-2)
  -  0.554 * h(1-item_03)
  +  0.851 * h(item_03-1)
  -   11.6 * h(2-item_10)
  +   10.4 * h(item_10-2)
  -  0.807 * h(1-item_24)
  +  0.581 * h(item_24-1)
  +  0.869 * h(17.319-hour)*dayTue
  -  0.656 * h(17.319-hour)*dayThu
  -   1.57 * h(18.023-hour)*dayFri
  -   1.39 * h(hour-18.023)*dayFri
  -    1.7 * h(18.629-hour)*daySat
  -   2.86 * h(hour-18.629)*daySat
  +   1.16 * h(distance-3.84)*dayFri
  -  0.561 * h(5.02-distance)*daySat
  +    2.1 * h(distance-5.02)*daySat
  -   11.3 * h(1-item_01)*item_10
  +   9.95 * h(item_01-1)*item_10
  -   1.43 * h(1-item_10)*daySat
  -   2.55 * h(item_10-1)*daySat
  -  0.578 * h(17.319-hour)*h(distance-3.54)
  +  0.324 * h(17.319-hour)*h(3.54-distance)
  +   1.05 * h(1-item_01)*h(item_09-1)
  -  0.546 * h(1-item_01)*h(1-item_09)</code></pre>
</div>
</div>
</details><div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>I just made the package; it would probably be called “experimental.” The syntax below may change in the future.</p>
</div>
</div>
<p>The adjusted package requires the use of the fitted model as well as the initial training set. The main function <code><a href="https://rdrr.io/pkg/adjusted/man/nn_adjust.html">nn_adjust()</a></code> has those two arguments:</p>
<div class="cell">
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">adj_obj</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://rdrr.io/pkg/adjusted/man/nn_adjust.html">nn_adjust</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">mars_fit</span>, training <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">delivery_train</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
</div>
<p>and pretty much does <em>nothing</em> at this point. We don’t even need to specifiy the number of neighbors until prediction/adjustment time:</p>
<div class="cell">
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predict the first validation row: </span></span>
<span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">x_0</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">delivery_val</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://dplyr.tidyverse.org/reference/slice.html">slice</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span>
<span></span>
<span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Original prediction:</span></span>
<span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">mars_fit</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">x_0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
  .pred
  &lt;dbl&gt;
1  29.1</code></pre>
</div>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Same:</span></span>
<span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">adj_obj</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">x_0</span>, neighbors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
  .pred
  &lt;dbl&gt;
1  29.1</code></pre>
</div>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adjust using 3 most similar samples</span></span>
<span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">adj_obj</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">x_0</span>, neighbors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 1
  .pred
  &lt;dbl&gt;
1  29.5</code></pre>
</div>
</div>
<p>So how many neighbors should we use? Let’s try different values and compute the RMSE for the validation set:</p>
<div class="cell">
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">val_pred</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;-</span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>neighbors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span></span>
<span>    .pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">neighbors</span>, </span>
<span>                <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://generics.r-lib.org/reference/augment.html">augment</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">adj_obj</span>, new_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">delivery_val</span>, neighbors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">.x</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span>,</span>
<span>    rmse <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://purrr.tidyverse.org/reference/map.html">map_dbl</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">.pred</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://yardstick.tidymodels.org/reference/rmse.html">rmse_vec</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">.x</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">time_to_delivery</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">.x</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">.pred</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span>
<span>  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
</div>
<p>The RMSE profile looks fairly common (based on our experiences with Cubist). The 1-NN model is <em>awful</em> since it is over-fitting to a single data point. As we increase the number of neighbors the RMSE drops and eventually surpasses the results without any adjustment:</p>
<div class="cell">
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">val_pred</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">neighbors</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">rmse</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RMSE (validation)"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="https://blog.aml4td.org/posts/post-hoc-nearest-neighbors-prediction-adjustments/index_files/figure-html/rmse-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Let’s compute the percent improvement relative to the no-adjustment case:</p>
<div class="cell">
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">val_pred_0</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">val_pred</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">neighbors</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://purrr.tidyverse.org/reference/pluck.html">pluck</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rmse"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span>
<span></span>
<span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">val_pred</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>pct_imp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">val_pred_0</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">rmse</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">val_pred_0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">neighbors</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">pct_imp</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scales</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">::</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;"><a href="https://scales.r-lib.org/reference/percent_format.html">percent</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span>  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Percent Imprvement (validation)"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="https://blog.aml4td.org/posts/post-hoc-nearest-neighbors-prediction-adjustments/index_files/figure-html/res-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>For these data, the best case is a 1.9% improvement in the RMSE. That’s not a game changer, but it is certainly helpful if every little bit of performance is important.</p>
<p>I made this package because the tidymodels group is finally focusing on <em>post-processing</em>: things that we can do to the model predictions to make them better. Another example is model calibration methods.</p>
<p>Our goal is to let you add post-processing steps to the workflow and tune/optimize these in the same way as pre-processing parameters or model hyperparameters.</p>



 ]]></description>
  <category>post-processing</category>
  <category>nearest neighbors</category>
  <category>regression</category>
  <category>tidymodels</category>
  <guid>https://blog.aml4td.org/posts/post-hoc-nearest-neighbors-prediction-adjustments/</guid>
  <pubDate>Wed, 10 Apr 2024 04:00:00 GMT</pubDate>
</item>
<item>
  <title>February 2024 Talks</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/2024-03-talks/</link>
  <description><![CDATA[ 




<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/2024-03-talks/pdp-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>One keynote and one tutorial last month (both new).</p>
<p>On March 19th, I gave the final keynote at the inaugural <em>Pharmaceutical Data Science Conference</em> at the University of Connecticut. The talk was called “What Happens After the Model?”</p>
<blockquote class="blockquote">
<p>Machine learning models are everywhere now. We must spend more time on what happens before and after the model fit to build higher-quality algorithms. This talk will describe a set of post-model activities that can improve the fit and also ensure that, when deployed, it is used effectively.</p>
</blockquote>
<p>You can find the slides at <a href="https://topepo.github.io/2024_PharmaDS/"><code>topepo.github.io/2024_PharmaDS/</code></a> and these contain a link to the sources.</p>
<p>Second was tutorial for the Statistical Society of Australia called “Introduction to Machine Learning with tidymodels”. The slides are at <a href="https://topepo.github.io/2024_SSA_SCV/"><code>topepo.github.io/2024_SSA_SCV/</code></a> and the sources are at <a href="https://github.com/topepo/2024_SSA_SCV"><code>github.com/topepo/2024_SSA_SCV</code></a>. A huge thanks go to <a href="https://www.simonpcouch.com/">Simon Couch</a> who write the first (very slick) section of the slides.</p>



 ]]></description>
  <category>R</category>
  <category>presentations</category>
  <guid>https://blog.aml4td.org/posts/2024-03-talks/</guid>
  <pubDate>Tue, 09 Apr 2024 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Predictive Survival Analysis</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/tidymodels-survival-models/</link>
  <description><![CDATA[ <p>The tidymodels group just released new versions of the core packages that enable (among other things) models for outcomes with censoring.</p>
<p><a href="https://en.wikipedia.org/wiki/Censoring_(statistics)">Censoring</a> is a situation, usually seen in time-to-event data, where we have <em>partial information</em>. For example, suppose we order something online that is expected to be delivered in 2 days. After a day, we don’t know the actual delivery time, but we know that the value is at least a day. This data point is <em>right censored</em> at a value of 1 day.</p>
<p><a href="https://www.tidymodels.org/learn/#category=survival%20analysis">tidymodels.org</a> has a few articles on modeling these data with the new functionality.</p>
<p>The main distinction for these models is how you quantify model performance. Most modern survival models don’t focus on the predicted event time but emphasize predicting the probability of the event not occurring (e.g., surviving) up to time point <img src="https://latex.codecogs.com/png.latex?t_0">. Because of this, we need to use dynamic performance metrics: these are metrics that judge performance at different points in time. Here’s a plot from an analysis where the Brier statistic is computed over a relevant time range:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="https://blog.aml4td.org/posts/tidymodels-survival-models/brier-scores-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>In this case, the large Brier score values at the first time point indicates mediocre performance. As the <em>evaluation time</em> progresses, the score becomes smaller (which is good) and the model does very well.</p>
<p>To include this type of model, there weren’t many syntax changes:</p>
<ul>
<li>Many functions now have an <code>eval_time</code> argument to take a vector of time points to evaluate performance measures.</li>
<li>There are some new <a href="https://yardstick.tidymodels.org/reference/index.html#dynamic-survival-metrics">performance statistics</a>.</li>
<li>Before modeling, you should probably create a <a href="https://rdrr.io/cran/survival/man/Surv.html"><code>Surv</code></a> object.</li>
</ul>
<p>Hopefully, we will soon be doing specific tidymodels tutorials on this subject (perhaps at useR). We also have two talks accepted at <a href="https://posit.co/conference/">Posit Conf</a> later this year.</p>



 ]]></description>
  <category>tidymodels</category>
  <category>survival analysis</category>
  <category>censoring</category>
  <category>R</category>
  <guid>https://blog.aml4td.org/posts/tidymodels-survival-models/</guid>
  <pubDate>Sun, 07 Apr 2024 04:00:00 GMT</pubDate>
  <media:content url="https://blog.aml4td.org/posts/tidymodels-survival-models/brier-scores-1.svg" medium="image" type="image/svg+xml"/>
</item>
<item>
  <title>Two New Preprocessing Chapters</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/two-new-preprocessing-chapters/</link>
  <description><![CDATA[ 




<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/two-new-preprocessing-chapters/encoded.svg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We just released two new chapters: “Transforming Numeric Predictors” and “Working with Categorical Predictors.”</p>
<p>The first talks about simple transformations of scale and outlier mitigation. It also discusses the important topic of when and how preprocessors should be trained.</p>
<p>The second new chapter introduces basic indicator/dummy variables and more complex encoding methods using hashing and target encodings.</p>
<p>The <a href="https://tidymodels.aml4td.org/">tidymodels code</a> for these chapters will be forthcoming in a few weeks; the tidymodels group has a series of CRAN releases underway, and there are some huge new features that we are documenting and writing technical materials for.</p>
<p>Also, we’ve moved some content out of our new chapter four and into an upcoming chapter on <em>embeddings</em>. That will discuss PCA, PLS, <a href="https://github.com/aml4td/website/pull/29">multidimensional scaling</a>, and other tools.</p>
<p>Finally, we are always interested in reviewers. If you are well-versed in a particular subject, let us know and we can add you as a reviewer for pull requests.</p>



 ]]></description>
  <category>transformations</category>
  <category>effect encodings</category>
  <category>indicator variables</category>
  <guid>https://blog.aml4td.org/posts/two-new-preprocessing-chapters/</guid>
  <pubDate>Mon, 18 Mar 2024 04:00:00 GMT</pubDate>
</item>
<item>
  <title>2024 Tidymodels User Survey</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/2024-tidymodels-user-survey/</link>
  <description><![CDATA[ 




<hr>
<p>In the tidymodels group, we re-evaluate our development roadmap after a major development epoch. In this case, we are finishing up extended support for censored data models (more on that later).</p>
<p>We always want community input into our direction. So please take a look at our tidymodels survey for 2024 priorities <a href="https://www.tidyverse.org/blog/2024/02/tidymodels-2024-survey/">blog post</a> and <strong>then take the</strong> <a href="https://conjoint.qualtrics.com/jfe/form/SV_aWw8ocGN5aPgeZE"><strong>survey</strong></a>.</p>
<p>While it’s not a guarantee, we do take it into account. For example, I was not really interested in creating a stacking ensemble package. However, it was rated very high in past surveys (here’s an example of some of those results). That helped lead one of our <del>former interns</del> group members to make the <a href="https://stacks.tidymodels.org/">stacks package</a>.</p>
<p>A few things are somewhat in process now, so we left those off the list. Our original list of possibilities had almost two dozen entries; we’ve whittled it down to less than ten for the survey.</p>
<p>(The photo is a NASA/JPL/SSI image of the hexagon on Saturn’s north pole)</p>



 ]]></description>
  <category>tidymodels</category>
  <category>R</category>
  <guid>https://blog.aml4td.org/posts/2024-tidymodels-user-survey/</guid>
  <pubDate>Mon, 04 Mar 2024 05:00:00 GMT</pubDate>
  <media:content url="https://blog.aml4td.org/posts/2024-tidymodels-user-survey/saturn-hex.png" medium="image" type="image/png" height="123" width="144"/>
</item>
<item>
  <title>WTF Article</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/wtf-article/</link>
  <description><![CDATA[ 




<hr>
<p>Kjell and I have a new paper called “What They Forgot to Tell You about Machine Learning with an Application to Pharmaceutical Manufacturing.”</p>
<p>It is in the <a href="https://doi.org/10.1002/pst.2366"><em>Pharmaceutical Statistics</em></a> journal, but you can read the preprint <a href="https://kjell-stattenacity.github.io/Tutorial/">on the GitHub page</a>.</p>
<p>I co-opted the “WTF” aspect of it from a workshop that our friends called <a href="https://rstats.wtf/">“What They Forgot to Teach You About R”</a>. I thought a reviewer or two might balk, but all we got was a comment about the novel use of that acronym.</p>
<p>The article was written while we were gearing up for the <code>aml4td</code> book, and you can get a sampling of many of the points we’ll be making there. We’ll also use a similar data set in a few chapters.</p>



 ]]></description>
  <category>publications</category>
  <guid>https://blog.aml4td.org/posts/wtf-article/</guid>
  <pubDate>Fri, 01 Mar 2024 05:00:00 GMT</pubDate>
  <media:content url="https://blog.aml4td.org/posts/wtf-article/wtf.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Progress Update (February 2024)</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/2024-02-progress-update/</link>
  <description><![CDATA[ 




<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/2024-02-progress-update/preproc.png" class="quarto-figure quarto-figure-center figure-img" height="150"></p>
</figure>
</div>
<p>Since the last update on 2023-11-20, we have a few new sections and chapters.</p>
<p>The short-term goal is to have good first drafts of all of the “Preparation” chapters. As of 2024-02-26, they are:</p>
<ul>
<li>Initial Data Splitting (<a href="https://aml4td.org/chapters/initial-data-splitting.html">drafted</a>)</li>
<li>Transforming Numeric Predictors (<a href="https://github.com/aml4td/website/blob/main/chapters/numeric-predictors.qmd">drafted</a> but not published)</li>
<li>Working with Categorical Predictors (<a href="https://github.com/aml4td/website/pull/11">waiting for review</a>)</li>
<li>Embeddings
<ul>
<li>Linear methods (PCA, PLS, etc) not drafted</li>
<li>MDS sections (<a href="https://github.com/aml4td/website/pull/11">waiting for review</a>)</li>
<li>Other methods (nearest shrunken centroids, etc) in progress</li>
</ul></li>
<li>Interactions and Nonlinear Features
<ul>
<li>Interactions (<a href="https://github.com/aml4td/website/pull/32">waiting for review</a>)</li>
<li>Spline section (in progress, almost finished)</li>
<li>Discretization (in progress, almost finished)</li>
</ul></li>
<li>Missing Data (started)</li>
</ul>
<p>We’ll update the website once the first three chapters listed above have good drafts. Another update will follow when the others are done.</p>



 ]]></description>
  <category>preprocessing</category>
  <category>updates</category>
  <guid>https://blog.aml4td.org/posts/2024-02-progress-update/</guid>
  <pubDate>Tue, 27 Feb 2024 05:00:00 GMT</pubDate>
  <media:content url="https://blog.aml4td.org/posts/2024-02-progress-update/preproc.png" medium="image" type="image/png" height="55" width="144"/>
</item>
<item>
  <title>New Location, Same Content</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/new-location-same-content/</link>
  <description><![CDATA[ 




<hr>
<p>This is the new home for the Applied Predictive Modeling blog.</p>
<p>We’ve moved it here, along with the previous blog posts, because we’re now using a format that is much easier to work with (<a href="https://quarto.org/">Quarto</a>). This will make it a lot easier to create posts<sup>1</sup>.</p>
<p>The blog is starting back up since we are actively developing our new (third) book called <em>Applied Machine Learning for Tabular Data</em> (<a href="https://aml4td.org/">aml4td</a>). We’ll post progress updates, requests for community help, discussions of technical matters, and other topics.</p>
<p>We kept the old blog name, which might be a little confusing since we are focusing on a different book. First, we wanted our posts in the same location; adding content in a new place was awkward. Second, the new book has similar topics and I’d expect we’d put similar content here.</p>
<p>Instead of having discussions inside the blog posts, we’ll create <a href="https://github.com/aml4td/blog/issues">GitHub issues</a> when we ask for community feedback and folks can respond there.</p>
<p>(The banner image is by <a href="https://unsplash.com/photos/tree-leaves-macro-photography-Jq3WI9IQgEs?utm_content=creditShareLink&amp;utm_medium=referral&amp;utm_source=unsplash">Dmytro Tolokonov</a>)</p>




<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Our old site was started around 2010. GitHub was barely a thing and we were years away from R’s markdown/rmarkdown/blogdown packages. We used Squarespace to host the blog, and it was fine but unwieldy for what we were doing.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>books</category>
  <category>blog</category>
  <guid>https://blog.aml4td.org/posts/new-location-same-content/</guid>
  <pubDate>Mon, 26 Feb 2024 05:00:00 GMT</pubDate>
  <media:content url="https://blog.aml4td.org/posts/new-location-same-content/dmytro-tolokonov-Jq3WI9IQgEs-unsplash.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>2022 tidymodels user survey</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/2022-tidymodels-user-survey/</link>
  <description><![CDATA[ 




<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/2022-tidymodels-user-survey/Screen+Shot+2021-10-07+at+1.25.38+PM.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We are conducting another survey to see where users would like us to spend our development time.</p>
<p>Here’s a link to <a href="https://conjoint.qualtrics.com/jfe/form/SV_3gtKaK8G1Z1JC50?Q_CHL=social&amp;Q_SocialSource=tidyverseblog">the survey</a>!</p>
<p>(This article was originally posted at <a href="http://appliedpredictivemodeling.com/blog/2021/10/7/2022-tidymodels-user-survey"><code>http://appliedpredictivemodeling.com</code></a>)</p>



 ]]></description>
  <category>R</category>
  <category>RStudio</category>
  <category>tidymodels</category>
  <guid>https://blog.aml4td.org/posts/2022-tidymodels-user-survey/</guid>
  <pubDate>Thu, 07 Oct 2021 04:00:00 GMT</pubDate>
</item>
<item>
  <title>tidymodels updates and voting!</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/tidymodels-updates-and-voting/</link>
  <description><![CDATA[ 




<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/tidymodels-updates-and-voting/tm-banner-small.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>While I’m still supporting <code>caret</code>, the majority of my development effort has gone into the tidyverse modeling packages (called <em>tidymodels</em>).</p>
<p>If you’ve never heard of this, we have just made an excellent learning resources at <a href="https://www.tidymodels.org/"><code>tidymodels.org</code></a>. You might consider focusing on the <a href="https://www.tidymodels.org/start/"><em>Get Started</em></a> pages.</p>
<p>Another item of note: help us <em>guide development</em> of this ecosystem by voting for new features! Vote <a href="https://twitter.com/juliasilge/status/1254879555979849729?s=20&amp;t=FhcmAZLKtfBvp_P7PDkzkw">here</a>.</p>
<p>(This article was originally posted at <a href="http://appliedpredictivemodeling.com/blog/2020/4/27/tidymodels-updates-and-voting"><code>http://appliedpredictivemodeling.com</code></a>)</p>



 ]]></description>
  <category>R</category>
  <category>tidymodels</category>
  <guid>https://blog.aml4td.org/posts/tidymodels-updates-and-voting/</guid>
  <pubDate>Mon, 27 Apr 2020 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Slides from R/Pharma</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/slides-from-rpharma/</link>
  <description><![CDATA[ 




<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/slides-from-rpharma/tpost_lung.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>My slides from the R/Pharma conference on “Modeling in the Tidyverse” are in <a href="RPharma_18_Kuhn.pdf">pdf format</a> as well as the <a href="RPharma_18_Kuhn.zip">HTML version</a>.</p>
<p>(Joe Cheng just killed it in his shiny presentation - see <a href="https://github.com/jcheng5/rpharma-demo">this repo</a>)</p>
<p>(This article was originally posted at <a href="http://appliedpredictivemodeling.com/blog/rpharma18"><code>http://appliedpredictivemodeling.com</code></a>)</p>



 ]]></description>
  <category>R</category>
  <category>presentations</category>
  <category>shiny</category>
  <category>tidyverse</category>
  <guid>https://blog.aml4td.org/posts/slides-from-rpharma/</guid>
  <pubDate>Thu, 16 Aug 2018 04:00:00 GMT</pubDate>
</item>
<item>
  <title>R/Medicine conference</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/rmedicine-conference/</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/rmedicine-conference/infer.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>I’ll be giving a talk at the R/Medicine conference on Sept 7th in New Haven CT.</p>
<p>My talk is on modeling in the tidyverse but there are some excellent speakers. Rob Tibshirani, Mike Lawrence, Jennifer Thompson, and a bunch of others will be there.</p>
<p>Take look at the <a href="http://r-medicine.com/">conference website</a> for more details.</p>



 ]]></description>
  <category>R</category>
  <category>presentations</category>
  <guid>https://blog.aml4td.org/posts/rmedicine-conference/</guid>
  <pubDate>Wed, 15 Aug 2018 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Podcast on Nonclinical Statistics</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/podcast-on-nonclinical-statistics/</link>
  <description><![CDATA[ 




<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/podcast-on-nonclinical-statistics/DjXIG2TV4AAHmX3.jpeg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p><a href="https://twitter.com/hugobowne">Hugo Bowne-Anderson</a> and I spoke about about data science in pharmaceuticals, the tidyverse, and more for the excellent <a href="https://www.datacamp.com/community/podcast">DataFramed</a> podcast from DataCamp. Listen to it <a href="https://www.datacamp.com/community/podcast/data-science-pharmaceuticals">here</a> or through your favorite blogging app.</p>
<p>(This article was originally posted at <a href="http://appliedpredictivemodeling.com/blog/2018/7/30/podcast-on-nonclinical-statistics"><code>http://appliedpredictivemodeling.com</code></a>)</p>



 ]]></description>
  <category>R</category>
  <category>presentations</category>
  <category>podcast</category>
  <guid>https://blog.aml4td.org/posts/podcast-on-nonclinical-statistics/</guid>
  <pubDate>Sat, 30 Jun 2018 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Early draft of our “Feature Engineering and Selection” book</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/early-draft-of-our-feature-engineering-and-selection-book/</link>
  <description><![CDATA[ 




<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/early-draft-of-our-feature-engineering-and-selection-book/model_process.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Kjell and I are writing another book on predictive modeling, this time focused on all the things that you can do with predictors. It’s about 60% done and we’d love to get feedback. You cna take a look at <a href="http://feat.engineering">http://feat.engineering</a> and provide feedback at <a href="https://github.com/topepo/FES/issues">https://github.com/topepo/FES/issues</a>.</p>
<p>The current TOC is:</p>
<ol type="1">
<li>Introduction</li>
<li>Illustrative Example: Predicting Risk of Ischemic Stroke</li>
<li>A Review of the Predictive Modeling Process</li>
<li>Exploratory Visualizations</li>
<li>Encoding Categorical Predictors</li>
<li>Engineering Numeric Predictors</li>
<li><em>Detecting Interaction Effects</em> (these later chapters are not finished yet)</li>
<li><em>Flattening Profile Data</em></li>
<li><em>Handling Missing Data</em></li>
<li><em>Feature Engineering Without Overfitting</em></li>
<li><em>Feature Selection</em></li>
</ol>
<p>(This article was originally posted at <a href="http://appliedpredictivemodeling.com/blog/2018/5/13/early-draft-of-our-feature-engineering-and-selection-book"><code>http://appliedpredictivemodeling.com</code></a>)</p>



 ]]></description>
  <category>R</category>
  <category>books</category>
  <category>feature selection</category>
  <category>feature engineering</category>
  <guid>https://blog.aml4td.org/posts/early-draft-of-our-feature-engineering-and-selection-book/</guid>
  <pubDate>Mon, 14 May 2018 04:00:00 GMT</pubDate>
</item>
<item>
  <title>tidyposterior slides</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/tidyposterior-slides/</link>
  <description><![CDATA[ 




<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/tidyposterior-slides/repeats.gif" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p><a href="https://topepo.github.io/tidyposterior/"><code>tidyposterior</code></a> is an R package for comparing models based on their resampling statistics. There are a few case studies on the webpage to illustrate the process.</p>
<p>I gave a talk at the <a href="https://odsc.com/boston">Open Data Science Conference (ODSC)</a> yesterday. A pdf of the slides are <a href="Comparing_Models_Using_Resampling_and_Bayesian_Methods.pdf">here</a>.</p>
<p>(This article was originally posted at <a href="https://appliedpredictivemodeling.com/blog/odsc18"><code>http://appliedpredictivemodeling.com</code></a>)</p>



 ]]></description>
  <category>R</category>
  <category>presentations</category>
  <category>tidyposterior</category>
  <category>resampling</category>
  <category>Bayesian models</category>
  <guid>https://blog.aml4td.org/posts/tidyposterior-slides/</guid>
  <pubDate>Fri, 04 May 2018 04:00:00 GMT</pubDate>
</item>
<item>
  <title>New Workshop in Washington DC (August)</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/new-workshop-in-washington-dc-august/</link>
  <description><![CDATA[ 




<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/new-workshop-in-washington-dc-august/Ames_lat.jpeg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>I’ll be conducting a workshop called <a href="https://www.rstudio.com/workshops/applied-machine-learning/">“Applied Machine Learning”</a> in Washington DC on August 15 and 16. The last one, at the RStudio conference, sold out quickly.</p>
<p>The 2 day course is a blend of <code>caret</code> and the newer tidy modeling pacakges (<code>recipes</code>, <code>rsample</code>, etc):</p>
<blockquote class="blockquote">
<p>Machine learning is the study and application of algorithms that learn from and make predictions on data. From search results to self-driving cars, it has manifested itself in all areas of our lives and is one of the most exciting and fast-growing fields of research in the world of data science.</p>
</blockquote>
<blockquote class="blockquote">
<p>This two-day course will provide an overview of using R for supervised learning. The session will step through the process of building, visualizing, testing, and comparing models that are focused on prediction. The goal of the course is to provide a thorough workflow in R that can be used with many different regression or classification techniques. Case studies on real data will be used to illustrate the functionality and several different predictive models are illustrated.</p>
</blockquote>
<blockquote class="blockquote">
<p>The course focuses on both high-level approaches to modeling (e.g., the caret package) and newer modeling packages in the tidyverse: recipes, rsample, yardstick, and tidyposterior. <strong>Basic familiarity with R and the tidyverse is required.</strong></p>
</blockquote>
<p>(This article was originally posted at <a href="https://appliedpredictivemodeling.com/blog/2018/4/10/new-workshop-in-washington-dc-august"><code>http://appliedpredictivemodeling.com</code></a>)</p>



 ]]></description>
  <category>R</category>
  <category>training</category>
  <category>caret</category>
  <category>tidyverse</category>
  <guid>https://blog.aml4td.org/posts/new-workshop-in-washington-dc-august/</guid>
  <pubDate>Tue, 10 Apr 2018 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Tidy Resampling Redux with Agricultural Economics Data</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/tidy-resampling-redux-with-agricultural-economics-data/</link>
  <description><![CDATA[ 




<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/tidy-resampling-redux-with-agricultural-economics-data/UNADJUSTEDNONRAW_thumb_265a.jpeg" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>(No statistical graphs in this one. This is what my dog Artemis looks like when she wants my attention during work hours.)</p>
<p>Mindy L. Mallory (<a href="https://twitter.com/ace_prof"><code>@ace_prof</code></a>) wrote a blog post on <a href="http://blog.mindymallory.com/2018/02/machine-learning-and-econometrics-model-selection-and-assessment-statistical-learning-style/"><em>Machine Learning and Econometrics: Model Selection and Assessment Statistical Learning Style</em></a> where she has a great description of the variance-bias tradeoff, resampling, and model complexity using some data from agricultural economics. I asked if I could take her code and make a more <a href="https://cran.r-project.org/web/packages/tidyverse/vignettes/manifesto.html">tidy</a> version of the resampling part. Here it is…</p>
<p>Here are the R packages that I’ll be using:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(tidyverse)</span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(rlang)</span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(rsample)</span>
<span id="cb1-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(yardstick)</span>
<span id="cb1-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(purrr)</span></code></pre></div>
<p>First, duplicate the process of reading in the data and adding two new columns:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1">stocks  <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">read.csv</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'http://blog.mindymallory.com/wp-content/uploads/2018/02/stocks.csv'</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> </span>
<span id="cb2-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as_tibble</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb2-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(</span>
<span id="cb2-4">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">USStockUse =</span> USEndingStocks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>USTotalUse, </span>
<span id="cb2-5">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">WorldStockUse =</span> ROWEndingStocks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>WorldTotalUse</span>
<span id="cb2-6">  )</span>
<span id="cb2-7">stocks</span></code></pre></div>
<pre><code>## # A tibble: 43 x 8
##     Year USEndingStocks ROWEndingStocks USTotalUse
##    &lt;int&gt;          &lt;dbl&gt;           &lt;int&gt;      &lt;dbl&gt;
##  1  1975           633.           36411      5767.
##  2  1976          1136.           39491      5789.
##  3  1977          1436.           40833      6207.
##  4  1978          1710.           47957      6995.
##  5  1979          2034.           59481      7604.
##  6  1980          1392.           67180      7282.
##  7  1981          2537.           62725      6975.
##  8  1982          3523.           60273      7249.
##  9  1983          1006.           63421      6693.
## 10  1984          1648.           76287      7032.
## # ... with 33 more rows, and 4 more variables:
## #   WorldTotalUse &lt;int&gt;, PriceRecievedFarmers &lt;dbl&gt;,
## #   USStockUse &lt;dbl&gt;, WorldStockUse &lt;dbl&gt;</code></pre>
<p>The blog post has an excellent description of cross-validation and looked at five different models that encoded the US and World stock-use predictors. Either a log- or inverse-transformation was applied and then polynomial basis functions were used on these features to demonstrate overfitting.</p>
<p>The blog post has some <code>for</code> loops to do the resampling and I volunteered to show how to do it with some tidy modeling packages.</p>
<section id="tidy-cross-validation" class="level3">
<h3 class="anchored" data-anchor-id="tidy-cross-validation">Tidy Cross-Validation</h3>
<p>First, let’s take the <em>easy</em> part. Instead of using <code>for</code> loops, we can use the new infrastructure in the tidyverse to resample the model. The <a href="https://topepo.github.io/rsample"><code>rsample</code></a> package has some functions for different types of resampling and we will use the same procedure as the original post:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">set.seed</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">918</span>)</span>
<span id="cb4-2">resamp_info <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">vfold_cv</span>(stocks, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">v =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb4-3">resamp_info</span></code></pre></div>
<pre><code>## #  5-fold cross-validation 
## # A tibble: 5 x 2
##   splits       id   
##   &lt;list&gt;       &lt;chr&gt;
## 1 &lt;S3: rsplit&gt; Fold1
## 2 &lt;S3: rsplit&gt; Fold2
## 3 &lt;S3: rsplit&gt; Fold3
## 4 &lt;S3: rsplit&gt; Fold4
## 5 &lt;S3: rsplit&gt; Fold5</code></pre>
<p>The first column in the tibble is a set of “<code>rsplit</code>” objects that define how the data are split for each fold of cross-validation. Each one fully and efficiently encapsulates everything what is needed to get the two divisions of the original data. In <code>rsample</code>, to avoid naming confusion, we label the two resulting data sets as:</p>
<ul>
<li><p>The <strong>analysis data</strong> are those that we selected in the resample. For a bootstrap, this is the sample with replacement. For 5-fold cross-validation, this is the 80% of the data. These data are often used to fit a model or calculate a statistic in traditional bootstrapping.</p></li>
<li><p>The <strong>assessment data</strong> are usually the section of the original data not covered by the analysis set. Again, in 5-fold CV, this is the 20% held out. These data are often used to evaluate the performance of a model that was fit to the analysis data.</p></li>
</ul>
<p>To get these partitions for the first split there are functions <code>analysis</code> and <code>assessment</code> that return the appropriate data frames when given an <code>rsplit</code>:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># printing just shows the #rows per analysis/assessment/overall</span></span>
<span id="cb6-2">resamp_info<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>splits[[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]]</span></code></pre></div>
<pre><code>## &lt;34/9/43&gt;</code></pre>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># data used for modeling:</span></span>
<span id="cb8-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">analysis</span>(resamp_info<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>splits[[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]])</span></code></pre></div>
<pre><code>## # A tibble: 34 x 8
##     Year USEndingStocks ROWEndingStocks USTotalUse
##    &lt;int&gt;          &lt;dbl&gt;           &lt;int&gt;      &lt;dbl&gt;
##  1  1975           633.           36411      5767.
##  2  1976          1136.           39491      5789.
##  3  1977          1436.           40833      6207.
##  4  1979          2034.           59481      7604.
##  5  1980          1392.           67180      7282.
##  6  1981          2537.           62725      6975.
##  7  1982          3523.           60273      7249.
##  8  1983          1006.           63421      6693.
##  9  1984          1648.           76287      7032.
## 10  1985          4040.           75069      6494.
## # ... with 24 more rows, and 4 more variables:
## #   WorldTotalUse &lt;int&gt;, PriceRecievedFarmers &lt;dbl&gt;,
## #   USStockUse &lt;dbl&gt;, WorldStockUse &lt;dbl&gt;</code></pre>
<p>The first model for the data contained the US stock-use data with an inverse transformation. Let’s side-step the polynomial model tuning for now and just fit a quadratic model. To make things easier, I’ll define a function that can be used to fit the model when given an <code>rsplit</code> object and return the holdout mean squared error (MSE):</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1">glm_results <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(split, ...) {</span>
<span id="cb10-2">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the data used ot fit the model aka the "analysis" set</span></span>
<span id="cb10-3">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># and fit the model with a formula given in the ...</span></span>
<span id="cb10-4">  mod <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">glm</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">analysis</span>(split), ...)</span>
<span id="cb10-5">  </span>
<span id="cb10-6">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get predictions on the other data (aka the "assessment" set </span></span>
<span id="cb10-7">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># and compute some metrics</span></span>
<span id="cb10-8">  holdout <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">assessment</span>(split)</span>
<span id="cb10-9">  </span>
<span id="cb10-10">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute performance using the yardstick package</span></span>
<span id="cb10-11">  rmse <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> holdout <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-12">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pred =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict</span>(mod, holdout)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-13">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rmse</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">truth =</span> PriceRecievedFarmers, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">estimate =</span> pred)</span>
<span id="cb10-14">  rmse<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb10-15">}</span></code></pre></div>
<p>We can use this with any formula since it is just passed to <code>glm</code> using the ellipses. For example to get the holdout MSE estimate for the first fold:</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">glm_results</span>(resamp_info<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>splits[[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]], <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">formula =</span> PriceRecievedFarmers <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">poly</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> USStockUse, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span></code></pre></div>
<pre><code>## [1] 1.67</code></pre>
<p>To get these statistics for all folds, <code>purrr::map_dbl</code> is used to add another column:</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1">resamp_info <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> resamp_info <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb13-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(</span>
<span id="cb13-3">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">model_1_deg_2 =</span> </span>
<span id="cb13-4">      <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">map_dbl</span>(</span>
<span id="cb13-5">        splits, </span>
<span id="cb13-6">        glm_results, </span>
<span id="cb13-7">        PriceRecievedFarmers <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">poly</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> USStockUse, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb13-8">      )</span>
<span id="cb13-9">  )</span>
<span id="cb13-10">resamp_info</span></code></pre></div>
<pre><code>## #  5-fold cross-validation 
## # A tibble: 5 x 3
##   splits       id    model_1_deg_2
## * &lt;list&gt;       &lt;chr&gt;         &lt;dbl&gt;
## 1 &lt;S3: rsplit&gt; Fold1         1.67 
## 2 &lt;S3: rsplit&gt; Fold2         0.558
## 3 &lt;S3: rsplit&gt; Fold3         0.596
## 4 &lt;S3: rsplit&gt; Fold4         9.58 
## 5 &lt;S3: rsplit&gt; Fold5         0.248</code></pre>
<p>That’s a lot of variation in the outcome! The mean value is fairly consistent with the blog post though:</p>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1">resamp_info <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">select</span>(model_1_deg_2) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">colMeans</span>()</span></code></pre></div>
<pre><code>## model_1_deg_2 
##          2.53</code></pre>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MSE = 2.675 in the blog post</span></span></code></pre></div>
<p><em>K</em>-fold cross-validation is one of the noisiest resampling methods so this difference isn’t too surprising.</p>
<p>This same process could be repeated for each polynomial degree to get new columns for this model (we’ll discuss this below). The good things about doing things this way:</p>
<ul>
<li>It is a lot cleaner (so far) than doing <code>for</code> loops.</li>
<li>Other tidyverse infrastructure can be used. For example, <a href="https://topepo.github.io/tidyposterior"><code>tidyposterior</code></a> is a great way to do model comparisons with resampling and Bayesian analysis.</li>
<li>It is simple to change resampling methods. Suppose you wanted to change to a larger number of bootstrap resamples (given the variance shown above). The same infrastructure can be easily exchanged; <code>resample::bootstraps</code> is used in place of <code>rsample::vfold_cv</code>.</li>
</ul>
</section>
<section id="tidy-model-specification-maybe" class="level3">
<h3 class="anchored" data-anchor-id="tidy-model-specification-maybe">Tidy Model Specification (maybe)</h3>
<p>The model specification part is, for me, a lot more difficult to tidy. It would be good to be able to state what predictors that we want, specify the polynomial degree, and have a function to generate the appropriate formula. The original post sensibly just types the terms out.</p>
<p>I spent some time thinking about how we could use <a href="https://adv-r.hadley.nz/expressions.html">expressions</a> and tidy evaluation (<a href="https://t.co/xEhCKne2mM">video from Hadley</a>) to make it a little less script-like. The problem is that the solution took me a while to write and, arguably, it doesn’t really buy you much more than the original code (apart from the potential copy/paste duplication errors).</p>
<p>In any case, the function uses <code>rlang</code> to manipulate expressions to make the formula. The inputs are expressions of <em>how</em> the predictors are used (i.e.&nbsp;log, inverse, etc.) and the degree. It captures the expression (without evaluating it), substitutes it into the polynomial function, then creates the formula:</p>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1">make_formula <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(..., <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">degree =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) {</span>
<span id="cb18-2">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Capture the expression so it is not evaluated</span></span>
<span id="cb18-3">  var_expr <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">exprs</span>(...)</span>
<span id="cb18-4">  </span>
<span id="cb18-5">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a template expression</span></span>
<span id="cb18-6">  inv_poly <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">quote</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">poly</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> x, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">degree =</span> degree))</span>
<span id="cb18-7"></span>
<span id="cb18-8">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Use a wrapper around rlang::call_modify to reverse the</span></span>
<span id="cb18-9">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># order of the arguments so that we can map over the</span></span>
<span id="cb18-10">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># predictor expressions</span></span>
<span id="cb18-11">  add_args <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(arg, call, ...)</span>
<span id="cb18-12">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">call_modify</span>(call, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> arg, ...)</span>
<span id="cb18-13">  </span>
<span id="cb18-14">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add the variables and the degree into the template</span></span>
<span id="cb18-15">  poly_expr <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">map</span>(var_expr, add_args, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">call =</span> inv_poly, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">degree =</span> degree)</span>
<span id="cb18-16">  </span>
<span id="cb18-17">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert to character</span></span>
<span id="cb18-18">  poly_char <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">map_chr</span>(poly_expr, deparse)</span>
<span id="cb18-19">  </span>
<span id="cb18-20">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert to a formula</span></span>
<span id="cb18-21">  poly_char <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">paste</span>(poly_char, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">collapse =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">" + "</span>)</span>
<span id="cb18-22">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.formula</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">paste</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"PriceRecievedFarmers ~"</span>, poly_char))</span>
<span id="cb18-23">}</span>
<span id="cb18-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># For example:</span></span>
<span id="cb18-25"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">make_formula</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>USStockUse, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">log</span>(WorldStockUse), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">degree =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span></code></pre></div>
<pre><code>## PriceRecievedFarmers ~ poly(x = 1/USStockUse, degree = 3) + poly(x = log(WorldStockUse), 
##     degree = 3)
## &lt;environment: 0x7fdf40b64840&gt;</code></pre>
<p>From here, we could use a bunch of <code>mutate</code> commands like the one shown above or write a slightly smaller <code>for</code> loop to work across the polynomial degrees. While the function above works well, the overall approach to working across models isn’t particularly satisfying.</p>
<p>Any suggestions? I’m on twitter <a href="https://twitter.com/topepos"><code>@topepos</code></a>!</p>
<p>(edit - fix fixed the formula call!)</p>
<p>(This article was originally posted at <a href="https://appliedpredictivemodeling.com/blog/2018/3/12/2s3j82ctkrhxugq7hf3myoeeb49k8u"><code>http://appliedpredictivemodeling.com</code></a>)</p>


</section>

 ]]></description>
  <category>R</category>
  <category>rsample</category>
  <category>resampling</category>
  <category>purrr</category>
  <category>tidyverse</category>
  <category>cross-validation</category>
  <guid>https://blog.aml4td.org/posts/tidy-resampling-redux-with-agricultural-economics-data/</guid>
  <pubDate>Mon, 12 Mar 2018 04:00:00 GMT</pubDate>
</item>
<item>
  <title>RStudio 2018 Conference Presentation and Materials</title>
  <dc:creator>Max Kuhn</dc:creator>
  <link>https://blog.aml4td.org/posts/rstudio-2018-conference-presentation-and-materials/</link>
  <description><![CDATA[ 




<hr>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://blog.aml4td.org/posts/rstudio-2018-conference-presentation-and-materials/bayes-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>We’ve released our videos of the talks at the 2018 RStudio conference. My talk was Modeling in the Tidyverse <a href="https://www.rstudio.com/resources/videos/modeling-in-the-tidyverse/">(video)</a> and I was also in the Tidyverse fireside chat <a href="https://youtu.be/Ol1FjFR2IMU?t=27720">(video)</a>. There are a lot of great talks on the <a href="https://www.rstudio.com/resources/webinars/">conference website</a>.</p>
<p>I also conducted a two day workshop on <code>caret</code> and the new modeling packages (<a href="https://topepo.github.io/recipes/"><code>recipes</code></a>, <a href="https://topepo.github.io/rsample/"><code>rsample</code></a>, <a href="https://topepo.github.io/tidyposterior/"><code>tidyposterior</code></a> and others) at the conference. The was no video of that, but all of the materials can be found in the <a href="https://github.com/topepo/rstudio-conf-2018">course GitHub repository</a>.</p>
<p>There will be at least one other workshop for this year on these topics. When that is finalized, I’ll post the details here and on <a href="https://twitter.com/topepos">on twitter</a>.</p>
<p>(the image above is from the workshop and is from <a href="https://topepo.github.io/tidyposterior/"><code>tidyposterior</code></a>)</p>
<p>(This article was originally posted at <a href="https://appliedpredictivemodeling.com/blog/2018/3/4/rstudio-2018-conference-presentation-and-materials"><code>http://appliedpredictivemodeling.com</code></a>)</p>



 ]]></description>
  <category>R</category>
  <category>presentations</category>
  <category>caret</category>
  <category>rsample</category>
  <category>recipes</category>
  <category>tidyposterior</category>
  <category>RStudio</category>
  <guid>https://blog.aml4td.org/posts/rstudio-2018-conference-presentation-and-materials/</guid>
  <pubDate>Sun, 04 Mar 2018 05:00:00 GMT</pubDate>
</item>
</channel>
</rss>
